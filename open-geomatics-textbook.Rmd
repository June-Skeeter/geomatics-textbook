--- 
title: "An Open Geomatics Textbook"
author: "UBC"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib]
biblio-style: apalike
link-citations: yes
github-repo:  ubc-geomatics-textbook/book
url: 'https\://github.com/ubc-geomatics-textbook/book/'
description: "Advancing teaching and learning in geomatics at UBC"
---

# Preface {-}

This is the very first part of the book, which will eventually include the textbook's introduction. For now, here's some useful info for you:

## Contacts 

Paul Pickell, paul.pickell@ubc.ca    
Evan Thornberry, evan.thornberry@ubc.ca    
Francois du Toit, fdutoit@mail.ubc.ca

## Project Wiki

[github.com/ubc-geomatics-textbook/docs/wiki](https://github.com/ubc-geomatics-textbook/docs/wiki)

## Style Guide
### Audience
1.	Audience is undergraduate of graduate student studying GIS, geomatics, and remote sensing with no prior knowledge in these subject areas (i.e., introductory).
2.	Assume only first year-level knowledge (or equivalent concurrent learning) of mathematics, science (biology, chemistry, physics), and geography.
3.	Assume a multicultural reader who is not necessarily familiar with Canadian geography and history.

### General Style
1.	Word spellings should follow *The Oxford Canadian Dictionary (2 ed.)*.
2.	Every chapter begins with 1-3 paragraphs of introductory text. The introductory text should be for general interest and not introduce any important terms that will be defined later in the chapter. The last sentence of this introductory text should summarize what students will learn.
3.	Posing questions to readers is encouraged in all sections. For example, “Have you ever wondered…?” “How do you think X relates to Y?”
4.	At every opportunity, authors should highlight Canadian examples of technology and science in geomatics. Examples of geomatics applications are highly encouraged in the Canadian context. For example, the following list of environmental management problems that are important to Canada should be discussed whenever possible:
    -	Northern communities
    -	First Nations
    -	Climate change
    -	Boreal forest
    -	Endangered wildlife
    -	Freshwater management and ecosystems
    -	Fisheries
    -	Glaciers/ice monitoring
    -	Environmental justice
    -	Resource extraction
    
### Learning Objectives
1.	Every chapter will have a numbered list of learning objectives that follow the introductory text.
2.	There should be no period at the end of each listed learning objective.

### Summary
1.	All learning objectives should be addressed in the summary section.
2.	The summary section should never introduce any new concepts, terms, or definitions and should never reference figures, tables, or equations.

### Key Terms
1.	Every chapter will have an alphabetical, but unnumbered list of key terms.
2.	At first mention in the chapter text, key terms should be boldened and defined.

### Headings and Labels
1.	Chapter titles should use title-case and are numbered.
2.	Chapter sub-titles are also numbered and in title-case. Sub-titles should go no lower than level 3 heading (i.e., 1.2.3).
3.	Level 4 headings are not numbered, all letters are capitalized, and should only be used in special call-out boxes:
    - LEARNING OBJECTIVES
    - REMEMBER THIS?
    - YOUR TURN!
    - CASE STUDY

### Formulae
1.	Do not format formulae using Microsoft Word or LaTeX. Instead, formulae should be formatted with [RMarkdown](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html).
2.	Coordinates and Greek letters should always be formatted as formulae with RMarkdown.

### Units
1.	Standard International (SI) units should be used for the following:
    -	Length = meter (m)
    -	Time = second (s)
    -	Amount of substance = mole (mole)
    -	Electric current = ampere (A)
    -	Temperature = Kelvin (K)
    -	Luminous intensity = candela (cd)
    -	Mass = Kilogram (kg)
2.	Angle degrees are preferred over radians (rad) when referencing geographic position.
3.	Rates should be expressed with a dot operator and negative exponent rather than a divisor (e.g., m·s-1 or W·m-2).

### Numbers
1.	Scientific notation is the preferred way to represent large and small numbers and should use the × operator (not dot or asterisk) and be formatted as a formula (see Formulae): 1 × 102.
2.	Scientific notation should be limited to four significant figures (e.g., 1.234 × 100) except for specific numbers where the precision is important or meaningful like the speed of light (2.99792458 × 108 m·s-1) or Planck’s constant (6.62607004 × 10-34 J·s-1).
3.	Constants (like above) and other physical variables should use [common notations](https://en.wikipedia.org/wiki/List_of_common_physics_notations) (e.g., c for speed of light and h for Planck’s constant) and be formatted as formulae (see Formulae).

### Dates and times
1.	The Gregorian calendar should be adopted for recent dates. In these cases, use Common Era (C.E.) to indicate dates after 0 A.D. and Before Common Era (B.C.E.) for dates before 0 A.D.
    -	For specific recent dates, use the format “20 February 2021” and omit C.E.
    -	If many dates need to be summarized in a table, use the format “DD-MM-YYYY”
2.	Times should be specified in either Local Standard Time (LST) or Coordinated Universal Time (UTC) using a 24-hour clock:
    -	00:00 = 12 A.M. midnight LST
    -	12:00 = 12 P.M. noon LST
    -	23:00 = 11 P.M. LST
3.	For non-recent dates or when referring to geologic time scales, use the following:
    -	Thousands of years before present = kilo annum (ka)
    -	Millions of years before present = mega annum (Ma)
    -	Billions of years = giga annum (Ga)

### Tables
1.	Tables are numbered in the order that they appear in text and begin with the number of the chapter:
    -	Table 1 in Chapter 1  = 1.1
2.	A short, descriptive caption should be written for a table.
3.	Tables should only include information that is discussed or referenced in the chapter text.
4.	Every table must be referenced in the chapter text.

### Code blocks
1.	Avoid code blocks in chapter text. Instead, try to place code blocks in TRY THIS! or CASE STUDY sections.
2.	Only R code blocks should be embedded using [RMarkdown](https://bookdown.org/yihui/rmarkdown/r-code.html).

### Abbreviations
1.	Abbreviations are shortened form of a word or phrase and should be punctuated with periods:
    -	e.g.
    -	Dr.
    -	Ph.D.

### Initialisms
1.	Initialisms are the first letters of several words and should always be defined at first use in the chapter text regardless if the initialism is introduced and defined in an earlier chapter.
2.	Do not introduce initialisms in figure or table captions or table text.
3.	Except for the specific cases in this style guide, do not punctuate initialisms with periods:
    -	AVHRR
    -	NDVI

### Acronyms
1.	Acronyms are combinations of the first letters of several words and are pronounced as words. Acronyms should never be punctuated with periods.
2.	Many satellites and remote sensing systems have acronyms that vary capitalization.
3.	Following are some preferred acronyms:
    -	Light Detection and Ranging = LiDAR
    -	Radio Detection and Ranging = RADAR
    -	Moderate Resolution Imaging Spectroradiometer = MODIS

### Punctuation
1.	Use serial comma (Oxford comma) in lists: Yukon, Northwest Territories, and Nunavut.
2.	Use italics for internal dialogue or when you infer what the reader might be thinking:
    - “At this point, you might be wondering, *why am I reading this sentence?*”
3.	Avoid the use of semi-colons.
4.	Use and punctuate common Latin abbreviations with periods:
    -	“For example” = exempli gratia (e.g.)
    -	“That is” = is est (i.e.)
    -	“And other similar things” = et cetera (etc.)
5.	Avoid phrases in parentheses () or brackets []. Instead, place the phrase in a proper sentence.
6.	Use single spaces between sentences.
7.	Use double quotation marks for direct quotes, but avoid reproducing verbatim large texts. Paraphrasing with proper citation is preferred to direct quotation.
8.	Bullet points are preferred over long lists in sentences.

### Citations
1.	Style should follow American Psychological Association (APA) format.
2.	In-text references are encouraged where necessary, especially in case studies.
3.	References and Recommended Readings section is placed at end of each chapter. Where possible, Recommended Readings should be populated with Open Educational Resources.


<!--chapter:end:index.Rmd-->

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library("dplyr")
library("rgdal")
library("leaflet")
library("xtable")
library("plyr")
library("dplyr")
```

# Relational Databases {#relational-databases}

You have almost certainly used a relational database in some form during your life, probably without even realizing it. Relational databases are foundational for information management in a GIS. In this chapter, we will look at the formal construction of relational databases, how they are used across a wide range of fields, and how we can use them to analyze spatial and aspatial information for environmental management.

:::: {.box-content .learning-objectives-content}

::: {.box-title .learning-objectives-top}
#### Learning Objectives {-}
::: 

1. Identify the purpose of Relational Database Management Systems in GIS
2. Describe the elements of relational databases
3. Practice applying relational algebra and Boolean logic to relations
4. Recognize the uses of different keys for joining and relating information
5. Understand how to query relational databases in order to extract or produce new information

::::

### Key Terms {-}

Relational Database Management Systems, Tables, Relations, Rows, Tuples, Records, Columns, Attributes, Items, Structured Query Language, Boolean Logic, Relational Algebra, Entity-Relationship Model, Cartesian Product, Schema, Unary, Binary, Georelational Data Model, Domain

## Relational database management systems

Suppose you have collected some data about some trees. You might have organized these data into a table, where each row represents a different plot, and each column represents some quantitative or qualitative measure about each record. How do you *manage* these data in order to extract useful information from your trees? This is where Relational Database Management Systems can help. A **Relational Database Management System (RDBMS)** is a software that allows the user to interact with tabular data. The basic services provided by a RDBMS include storing, querying, and manipulating relational databases. We say the databases are *relational* because they are based on a relational model first developed by Edgar Codd in the 1970s at IBM. The relational model for database management is distinguished from non-relational models by the fact that data are stored in highly structured tables instead of some other format like documents. This distinction is important, because the vast majority of GIS software utilize the relational model for database management.

## Relational databases

Within a RDBMS, we find **relational databases**, which are highly structured tables comprised of rows and columns. In fact, a table in a relational database is called a **relation**, a row is a **tuple**, and a column is an **attribute**. Relational databases are a great way to store simple data structures that can be organized into a relation with tuples and attributes. When we say that a table or relation is "structured", we are referring to the fact that the data are organized according to a database **schema**, which is a set of constraints that ensure data integrity and consistency. For example, our set of trees likely all contain the same types of information and this can be easily organized into a relation. Suppose we measured the height, diameter at breast height (DBH), and species of each tree, then our relation would look like Figure 5.1.

![Figure 5.1 Tabular and spatial data are related by a Relational Database Management System (RDBMS) in a Geographic Information System (GIS). Images of Douglas-Fir and Western Hemlock trees by Natural Resources Canada, Canadian Forest Service, modified with permission. ](images/05-01-tabular-data-spatial-data.png){.center}

As you can see from the example above, there are two components to geospatial data: the tabular data containing tuples and attributes and the spatial data that contain the coordinate pairs for a projected or geographic coordinate system. This structure is known generically as the **georelational data model**. Many formats of geospatial data conform to the georelational data model, which stores a relation of tuples and attributes separately from another relation containing the geometry and coordinates. These two tables are then dynamically related to one another in a RDBMS using GIS software. You will almost never interact or see the relation that stores the geometry and coordinates of features contained in a relational database. Instead, the GIS software manages those files in the background for the purpose of displaying a set of features on a map, and you primarily interact with the tabular data stored in the relation of tuples and attributes.

The schema for the very simple example above would include the constraint and expectation that when we retrieve the height of a particular tree from the relation, it will be returned to us as an integer number and not a date. This logic is extended to all attributes so that types of values are never mixed and values are never unexpectedly changed by any database operation. That is to say, we can and often do intentionally change values in a relation, but any new values must conform to the database schema for a particular attribute, which may also be constrained by a range and type of potential values, known as an attribute **domain**.

More formally, a relation $R$ is a _subset_ of two sets, $A$ (tuples) and $B$ (attributes). The product of these sets $A×B$ is called the **Cartesian product**. In the same way that Cartesian coordinates are ordered pairs of values from two axes, the Cartesian product of two sets gives us an ordered pair of elements $(a,b)$ from sets $A$ and $B$, where $a$ is an element in the set $A$, written as $a∈A$, and $b$ is an element of set $B$, written as $b∈B$. Therefore, $R$ is both the Cartesian product as well as any subset of $A×B$.

![Figure 5.2 Cartesian product A×B of A (tuples) and B (attributes). Image by Quartl, CC BY-SA 3.0.](images/05-02-cartesian-product.png){.center}

There are some important rules to be followed for organizing data into a relation:

1. Each tuple must share the same attributes as all the other tuples;
2. Each attribute has a unique name and is of the same _type_ of data (i.e., integer, floating-point decimal, text, date, boolean, etc.);
3. The order of tuples and attributes can be rearranged without changing the meaning or integrity of the data;
4. Each value of an element in a relation (i.e., combination of tuple and attribute) is _logically_ accessible; and 
5. Each tuple is unique (i.e., no duplicate observations).

If any of the above rules are broken, then $R≠A×B$ and you are just looking at a plain-old table instead of a relation. In fact, Codd described a total of 13 rules for a RDBMS, but since this chapter is only a cursory introduction of RDBMS for GIS, you only need to be familiar with the five rules above. In this way, relational databases are comprised of relations that are highly structured by a schema, which allows the user to query, retrieve, update, and delete data using a RDBMS. At this point, you should understand that relational databases are highly structured so that we can apply logical expressions and languages to interact with the information contained within and between the relations. In the next two sections, we will look at how to apply two branches of mathematical logic to relations in order to extract useful information.

## Relational algebra

One of the fundamental jobs of a RDBMS is to apply relational algebra operations to relations stored in a relational database. Remember that we defined a relation as $R=A×B$ and that any subset of $A×B$ is also a relation. This transitive property of relations combined with the fact that relations are just sets allows us to apply set algebra. In other words, relational algebra operations take one relation as input and produce a new relation as an output without modifying the input relation. This new output relation can then be used as an input to another operation because it is also a relation.

### Selection

**Selection** is the simplest operation to understand and is probably the most-used in day-to-day GIS work. It does exactly what it sounds like, it retrieves a subset of a relation given some predicate or condition. For example, we could select all tree IDs from our relation $R$ in Figure 5.1 that have a height greater than 20 m. This would yield tree ID=5. Formally, selection is expressed as $σ_{predicate}(R)$ and the example above would be written as $σ_{height>20}(R)$, which evaluates to the following:

```{r, echo=FALSE}
ID <- 1:5
height <- c(14,18,16,25,20)
dbh <- c(26.8,30.5,28.7,36.0,34.6)
species <- c("Western Hemlock","Western Hemlock","Western Hemlock","Douglas-Fir","Douglas-Fir")
R <- data.frame(ID=ID,Height=height,DBH=dbh,Species=species)
names(R) <- c("ID","Height (m)", "DBH (cm)", "Species")
knitr::kable(
  R[which(R$`Height (m)`>20),], booktabs = TRUE, row.names = FALSE
)
```

### Projection

If selection is understood to operate on attributes to return tuples, then **projection** is an operation on tuples to return attributes. For example, suppose we are only interested in the height and DBH attributes for the trees. We would use projection to return this new subset of the relation. Formally, projection is expressed as $Π_{predicate}(R)$. Both projection and selection are referred to as **unary** operators because they only require a single relation as input. The example above would be expressed using the attributes that we want to preserve, so $Π_{height,dbh}(R)$, which evaluates to the following:

```{r, echo=FALSE}
knitr::kable(
  R[,c(-1,-4)], booktabs = TRUE, row.names = FALSE
)
```

At this point, it is important to emphasize the case of $Π_{species}(R)$, which evaluates to:

```{r, echo=FALSE}
spu <- unique(R$Species)
Tr <- data.frame(Species=spu)
knitr::kable(
  Tr, booktabs = TRUE, row.names = FALSE
)
```

Recall that the output of a relational algebra operation is also a relation. Remember the rule that a relation cannot have any duplicate tuples? Well, in the case of a 1-dimensional relation where we only have one attribute and several tuples, any duplicate values for the tuples must be eliminated, leaving us with only the two unique values "Douglas-Fir" and "Western Hemlock" when we project $R$ over $Species$. You should recognize now that this property of projection can be useful for identifying the unique values of any attribute, which is frequently needed when sorting through a relational database.

### Rename

**Rename** is an operator that allows us to assign a variable name to a relational algebra expression. This has the benefit of making it simpler to track or reuse previous operations in complex relational database algebra. For example, let $S = σ_{height>20}(R)$, then $Π_{species}(S)$ evaluates to:

```{r, echo=FALSE}
knitr::kable(
  data.frame(Species=R[which(R$`Height (m)`>20),4]), booktabs = TRUE, row.names = FALSE
)
```

### Set Union

Next we will introduce **binary** operators, that is, they take two relations as input. **Set Union** is one such operator that effectively appends one relation to another. The important rule for union is that both input relations must share the same number and type of attributes or "union compatible". Formally, set union is expressed as $S∪T$ where $S$ and $T$ are the two input relations. You can think of set union as simply concatenating the tuples of the two relations together. In other words, the tuples of $S$ are appended to the tuples of $T$ to generate a new output relation. For example, suppose that we make two subsets of our relation $R$ of trees:

$$
S = σ_{height>20}(R)
$$

$$
T = σ_{height≥20}(R)
$$

Then we can union these two relations back into our original relation $R$ as $S∪T$, which evaluates to:

```{r, echo=FALSE}
knitr::kable(
  R, booktabs = TRUE, row.names = FALSE
)
```

Formally, this would all be expressed as $σ_{height>20}(R)∪σ_{height≥20}(R)$ or $S∪T$, which in this case is also just equivalent to $R$. You should see that the result of union is an inclusion of all tuples, so semantically a union can be read as "the tuples in relation S _or_ the tuples in relation T". 

### Set Intersection

On the other hand, suppose that we want to define a new relation based on restricting the set of tuples that are in two different relations. This is known as **set intersection** and is formally expressed as $S∩T$. Just like union, intersection also requires that the two relations be union compatible. Suppose we have two relations defined by subsetting height by < 25 m and > 15 m:

$$S = σ_{height<25}(R)$$

```{r, echo=FALSE}
knitr::kable(
  R[which(R$`Height (m)`<25),], booktabs = TRUE, row.names = FALSE
)
```

$$T = σ_{height>15}(R)$$
```{r, echo=FALSE}
knitr::kable(
  R[which(R$`Height (m)`>15),], booktabs = TRUE, row.names = FALSE
)
```

There are 3 tuples that appear in both of these relations, so the intersection $S∩T$ would evaluate to:

$$S∩T$$
Semantically, set intersection is read as "the tuples in relation S _and_ the tuples in relation T". 

```{r, echo=FALSE}
knitr::kable(
  R[c(2,3,5),], booktabs = TRUE, row.names = FALSE
)
```

### Set Difference

**Set difference** returns the tuples that are unique in one relation relative to another relation, but both relations must be union compatible. Formally, difference is expressed as $S-T$, and just like mathematical subtraction, the order of relations in the set difference is important and non-commutative. For example, $σ_{height<25}(R)-σ_{height>15}(R)$ evaluates to:

```{r, echo=FALSE}
knitr::kable(
  R[1,], booktabs = TRUE, row.names = FALSE
)
```

and $σ_{height>15}(R)-σ_{height<25}(R)$ evaluates to:

```{r, echo=FALSE}
knitr::kable(
  R[4,], booktabs = TRUE, row.names = FALSE
)
```

Semantically, you would read the difference $S-T$ as "the tuples in relation $S$ minus any of the same tuples in relation $T$". 

### Cartesian Product

So far, we have seen the cases of mathematical addition (set union) and subtraction (set difference), but we can also apply multiplication and division. Multiplication of two relations is simply known as the **Cartesian product**. In the same way that a set of tuples and attributes can be multiplied to create a relation $R=A×B$, we can also multiply two relations together and they do not need to be union compatible. For example, if $S = Π_{height,dbh}(σ_{height<20}(R))$ evaluates to:

```{r, echo=FALSE}
Sr <- R[1:3,2:3]
knitr::kable(
  Sr, booktabs = TRUE, row.names = FALSE
)
```

and $T = Π_{ID,Species}(σ_{dbh>34}(R))$ evaluates to:

```{r, echo=FALSE}
Tr <- R[4:5,c(1,4)]
knitr::kable(
  Tr, booktabs = TRUE, row.names = FALSE
)
```

then the Cartesian product of $S×T$ evaluates to:

```{r, echo=FALSE}
i <- rep(R[4:5,1],3)
h <- rep(R[1:3,2],2)
d <- rep(R[1:3,3],2)
s <- rep(R[4:5,4],3)
df <- data.frame(i,h,d,s)
names(df) <- c("ID","Height (m)","DBH (cm)","Species")
knitr::kable(
  df, booktabs = TRUE, row.names = FALSE
)
```

### Set Divison

Finally, **set division** is an operation of division between two relations, and you can think of it semantically as, "all the values of an attribute in $R$ that are found with the tuples of $S$." Set division is expressed as $S÷T=U$ and like the Cartesian product and set difference, set division is non-commutative, so the order of $S$ and $T$ changes the value of $U$. 

For the next example of set division, we will introduce a new relation $S$, which is not a subset of $R$. Suppose, in addition to $R$, we have cataloged information about different tree species, some of which are in $R$ (these data are a small sample of a [full list of tree species codes](https://www.for.gov.bc.ca/hfp/publications/00026/fs708-14-appendix_d.htm#ad_02) commonly used in British Columbia, Canada):

```{r, echo=FALSE}
co <- c("AT","BB","CW","E","FD","HW","YC")
sp <- c("Trembling Aspen","Balsam Fir","Western Red Cedar","Birch","Douglas-Fir","Western Hemlock","Yellow Cedar")
S <- data.frame(Code=co,Species=sp)
knitr::kable(
  S, booktabs = TRUE, row.names = FALSE
)
```

Suppose we want to answer the question, _What are all the species codes that are present in our plot of trees?_ We can answer this question by first projecting $Species$ over $R$ to give relation $T=Π_{species}(R)$:

```{r, echo=FALSE}
Pt <- data.frame(Species=unique(R$Species))
knitr::kable(
  Pt, booktabs = TRUE, row.names = FALSE
)
```

Then, dividing $S$ by $T$, $S÷T=U$, can be formally expanded to:

$$
Π_{code}(S) - Π_{code}((Π_{code}(S) × T) - S)
$$

We read the first term $Π_{code}(S)$ as "the projection of the attributes of $S$ that are not in $T$". In our case, there is only one attribute in $S$ not in $T$, which is $Code$, so $Π_{code}(S)$ evaluates to:

```{r, echo=FALSE}
Ps <- data.frame(Code=unique(S$Code))
knitr::kable(
  Ps, booktabs = TRUE, row.names = FALSE
)
```

Then, $Π_{code}(S)×T$ is the Cartesian product of the previous projection and $T$, which yields a relation of all the combinations of $T$ with the attributes in $S$ that are not in $T$:

```{r, echo=FALSE}
Ct <- expand.grid(Ps$Code,Pt$Species)
names(Ct) <- c("Code","Species")
knitr::kable(
  Ct, booktabs = TRUE, row.names = FALSE
)
```

Next, we take the set difference between the Cartesian product above and $S$, $(Π_{code(S)×T)-S$, which has the effect of removing the tuples already observed in $S$. This leaves us with a relation that has all the "incorrect" code-species combinations:

```{r, echo=FALSE}
Ds <- Ct[paste0(Ct$Code,Ct$Species)%in%setdiff(paste0(Ct$Code,Ct$Species),paste0(S$Code,S$Species)),]
knitr::kable(
  Ds, booktabs = TRUE, row.names = FALSE
)
```

Next, we project $Code$, which again is the only attribute in $S$ not in $T$, from the set difference above $Π_{code}((Π_{code}(S) × T) - S)$, which yields:

```{r, echo=FALSE}
PDs <- data.frame(Code=unique(Ds$Code))
knitr::kable(
  PDs, booktabs = TRUE, row.names = FALSE
)
```

And finally, we take the set difference between $Π_{code}(S)$ and the projection above to obtain the code for the trees in our plot:

```{r, echo=FALSE}
U <- data.frame(Code=S[S$Species%in%setdiff(Pt$Species,PDs$Code),1])
knitr::kable(
  U, booktabs = TRUE, row.names = FALSE
)
```

You can think of set division as the inverse of a Cartesian product. However, just like division, the Cartesian product itself is non-commutative because it is a set of _ordered_ pairs. If $S$ contains a tuple that is not in $T$, then the Cartesian product of $S×T$ has a different order than would be the case if both $S$ and $T$ were identical. As an example, $S×T$ evaluates to:

```{r, echo=FALSE}
C.ut <- data.frame(do.call(expand.grid, lapply(list(U$Code,Pt$Species), unique)))
names(C.ut) <- c("Code","Species")
knitr::kable(
  C.ut, booktabs = TRUE, row.names = FALSE
)
```

and $T×S$ evaluates to:

```{r, echo=FALSE}
C.tu <- data.frame(do.call(expand.grid, lapply(list(Pt$Species,U$Code), unique)))
names(C.tu) <- c("Species","Code")
knitr::kable(
  C.tu, booktabs = TRUE, row.names = FALSE
)
```

Therefore, we cannot simply rewrite $S÷T=U$ as $U×T=S$, but we could express $U÷S=T$, which evaluates to $T$:

```{r, echo=FALSE}
knitr::kable(
  Pt, booktabs = TRUE, row.names = FALSE
)
```

We have now considered the eight primary relational algebra operators (selection, projection, rename, set union, set intersection, set difference, Cartesian product, and set division) that can be applied to relations in a RDBMS. In the next section, we will look at another set of logical operators known as Boolean algebra, which give rise to logical languages for interacting with a RDBMS.

## Boolean algebra

Whenever we create and solve an arithmetic or relational algebra expression, we usually focus on the _value_ of the output. In other words, $1+1$ evaluates to a value of $2$. But we often need to evaluate the _truth_ of a statement. For example, $1+1=2$ is a $true$ statement and $1+1=1$ is a $false$ statement. **Boolean algebra** seeks to express mathematical expressions in terms of _truth values_. Boolean truth values are usually expressed as $true$ or $false$, but it is also common in computer programming languages and GIS to see these encoded with values of $1$ for $true$ and $0$ for $false$. Attributes can also take on Boolean values of $true$ or $false$ as a data type. Boolean algebra uses equality and conditional operators, which we will consider next.

### Equality operators

You are probably already familiar with the basic equality operators used in Boolean algebra:
- $=$ "exactly equal to" (usually expressed with $==$)
- $>$ "greater than"
- $≥$ "greater than or equal to" (usually expressed with $>=$)
- $<$ "less than"
- $≤$ "less than or equal to" (usually expressed with $<=$)
- $≠$ "not equal to" (usually expressed with $!=$ or $<>$)

All of the equality operators above evaluate to logical $true$ or $false$ values. They are quite elementary, so we will not go into much detail except to show that these equality operators are the basis for forming more complex Boolean expressions. Basic arithmetic expressions can also be applied to Boolean truth values and it can be helpful to rewrite Boolean values with values of $1$ and $0$:

$true+true=2$
$true+false=1$
$false+false=0$
$true-true=0$
$true÷false=undefined$
$false÷true=0$
$true×true=1=true$
$5×false=0=false$

Multiplication of Boolean values is a special case where the expression will always result in a Boolean value. That is, multiplying any combination of $1$ and $0$ will always return $1$ or $0$. In other words, the domain of the input $[0,1]$ is equivalent to the domain of the output $[0,1]$, which is a property that is frequently exploited in GIS in order to concatenate more complex expressions. For example, the statement $true×(1+2=3)×(4>3)$ can be rewritten as $1×1×1$ and evaluates to $true$, while $true×(1+2=3)×(4<3)$ can be rewritten as $1×1×0$ and evaluates to $false$. 

Below are some examples of using equality operators and what they evaluate to:

$true=false$ can be rewritten as $1=0$, which is $false$.
$true>false$ can be rewritten as $1>0$, which is $true$.
$true≠false$ is $true$.
$1+1=1$ is $false$.
$2+3=4+1$ is $true$.

Next, we will look at how to apply arithmetic and equality expressions to relations and evaluate them in Boolean terms. We have already seen how predicates allow us to do set selection with relational algebra. For example, we know that q evaluates to:

```{r, echo=FALSE}
knitr::kable(
  R[which(R$`Height (m)`>15),], booktabs = TRUE, row.names = FALSE
)
```

If we were to break this down in Boolean terms, the statement $height>15$ applied to $R$ returns the following Boolean values for each tuple:

```{r, echo=FALSE}
Rtf <- R
Rtf$Boolean <- R$`Height (m)`>15
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

For another example, consider that $(height>15)×(species=WesternHemlock)$ evaluates to:

```{r, echo=FALSE}
Rtf$Boolean <- (R$`Height (m)`>15 & R$Species=="Western Hemlock")
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

We can also evaluate the equivalency between two attributes such as $height=dbh$, which evaluates to:

```{r, echo=FALSE}
Rtf$Boolean <- R$`Height (m)`==R$`DBH (cm)`
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

### Conditional operators

Now that we have a good understanding of equivalency operators, let us turn to consider conditional operators, which are also known as Boolean operators. Boolean operators are, in some ways, similar to some arithmetic operators except that they are based on natural language. There are three primary Boolean operators: $AND$, $OR$, $XOR$, and $NOT$. These operators are commonly used for database queries and with search engines, and indeed they form an important basis for query languages that are used to interact with an RDBMS. 

Consider the statement $(height>15)AND(species=WesternHemlock)$. This statement is equivalent to $(height>15)×(species=WesternHemlock)$ and evaluates to exactly what what we saw earlier:

```{r, echo=FALSE}
Rtf$Boolean <- (R$`Height (m)`>15 & R$Species=="Western Hemlock")
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

Figure 5.3 illustrates what is going on here, we are only returning the tuples that evaluate $true$ for both statements. Hence, Boolean $AND$ is equivalent to multiplying two Boolean truth values together. You should also recognize that a Boolean $AND$ is equivalent to what a set intersection $A∩B$ achieves between two relations.

![Figure 5.3 Boolean A AND B returns the area shaded blue.](images/05-03-boolean-and.png){.center}

If we do not want to be so restrictive, we could use Boolean $OR$ such as $(height>15)OR(species=WesternHemlock)$, which evaluates to:

```{r, echo=FALSE}
Rtf$Boolean <- (R$`Height (m)`>15 | R$Species=="Western Hemlock")
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

Figure 5.4 illustrates the case of the Boolean $OR$. As you can see, it returns everything where either of the statements evaluate to $true$, regardless if the other statement is $false$. You should also recognize that a Boolean $OR$ is equivalent to what a set union $A∪B$ achieves between two relations. 

![Figure 5.4 Boolean A OR B returns the area shaded blue.](images/05-04-boolean-or.png){.center}

Suppose we want to identify all the trees that are greater than 15 m, but not Western Hemlock. In this case, we would use the expression $(height>15)NOT(species=WesternHemlock)$, which evaluates to:

```{r, echo=FALSE}
Rtf$Boolean <- (R$`Height (m)`>15 & !R$Species=="Western Hemlock")
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

Figure 5.5 illustrates how Boolean $NOT$ essentially negates or inverts the statement that follows. In this case, instead of returning the Western Hemlock tuples, $NOT(species=WesternHemlock)$ returns "everything except" Western Hemlock, which is also equivalent to $species≠WesternHemlock$.

![Figure 5.5 Boolean A NOT B returns the area shaded blue.](images/05-05-boolean-not.png){.center}

Finally, the case of Boolean $XOR$ returns any tuples that are not $true$ for both statements, but are $true$ individually. This is known as the "e**X**clusive **OR**" because we are only returning the tuples that are exclusive based on both statements. For example, $(height>15)XOR(species=WesternHemlock)$ evaluates to:

```{r, echo=FALSE}
Rtf$Boolean <- (R$`Height (m)`>15 | R$Species=="Western Hemlock") & !(R$Species=="Western Hemlock"&R$`Height (m)`>15)
knitr::kable(
  Rtf, booktabs = TRUE, row.names = FALSE
)
```

Figure 5.6 illustrates how Boolean $XOR$ excludes all the tuples that evaluate to $true$ for both statements. In the example above, tuples ID=2 and ID=3 are excluded because both of the statements for height and species are $true$. 

![Figure 5.6 Boolean A XOR B returns the area shaded blue.](images/05-06-boolean-xor.png){.center}

## Joining relations

More often than not, information is stored in separate relations, even if that information is about the same features like lakes, forests, or cities. Remember that a relation cannot have any duplicate tuples. This rule encourages the efficient storage and retrieval of information because information can be dynamically related as needed. For example, consider the overwhelming amount of information that is collected during a census. During the last census in 2016, there were over 14 million households in Canada. Can you imagine wielding a relation with 14 million tuples? These households can be segmented geographically by province, metropolitan areas, municipalities, and census subdivisions as well as by socioeconomic themes such as Indigenous peoples, age, sex, education, income, labour, housing, language, and others. Thus, those 14 million households can be divided up into many smaller relations, which can be accessed and summarized geographically and thematically. Since these relations represent different geographies or themes on the same set (i.e., households), we need to be more specific about how exactly two relations get combined if, for example, we want to combine themes with geographies. For this reason, we have joins. 

### Keys

Like the Cartesian product, joins are always binary operations, requiring two relations as input. While the Cartesian product combines relations by ordering all pairs of the elements from the two relations, we need a different method for correctly linking the tuples in relation $R$ that correspond to the tuples of $S$. To do this, we rely on a common attribute called a **key**, which acts as an address between two relations. A **primary key** serves the purpose to identify the unique tuples in a relation and so it can be used to link other attribute information to those tuples. In a GIS, anytime that you create, copy or modify features such as points, lines or polygons, the newly created data layer (within the relational database) will be indexed with a primary key that counts from 1 to the number of features (tuples) $n$ or from 0 to $n-1$. For example, $ID$ in our relation $R$ serves as the primary key. There are other attributes in $R$ that also uniquely identify all the tuples, but why do you think $Height$ or $DBH$ would be a poor operational choice as a primary key for a large field campaign?

While the primary key identifies the unique tuples in relation $R$, another key called the **foreign key**, serves to locate the same tuples in another relation $S$. In other words, a join is defined by a common attribute that is shared between two relations, the primary key in $R$ and the foreign key in $S$. For example, $Species$ is a foreign key in $R$ and a primary key in $S$. The case of joining two relations using a set of attributes instead of a single attribute requires a **composite key**. For example, suppose we have a spatial dataset of all the municipalities across Canada. Some of these municipalities will share the same name, though they are in different provinces. Richmond is a city in British Columbia, Ontario, and Quebec. If we need to join census data to these spatial features, we would need to use a composite key comprised of $CityName$ and $ProvinceName$.

### Natural Join

A **natural join ** restrictively joins two relations based on a set of common attributes. In this way, natural join is similar to a set intersection in that we are only combining tuples that share an attribute value and any tuples that do not share an attribute value in the other relation are dropped from the output. However, a natural join does not require that two relations be union compatible like a set intersection. Instead, the only requirement is that at least one attribute is shared between the two relations and has the same domain. Formally, natural join is expressed as $R⋈S$. and is sometimes referred to as an inner join. As an example, consider our example relations $R$ and $S$:

$$R$$

```{r, echo=FALSE}
ID <- 1:5
height <- c(14,18,16,25,20)
dbh <- c(26.8,30.5,28.7,36.0,34.6)
species <- c("Western Hemlock","Western Hemlock","Western Hemlock","Douglas-Fir","Douglas-Fir")
R <- data.frame(ID=ID,Height=height,DBH=dbh,Species=species)
names(R) <- c("ID","Height (m)", "DBH (cm)", "Species")
knitr::kable(
  R, booktabs = TRUE, row.names = FALSE
)
```

$$S$$

```{r, echo=FALSE}
co <- c("AT","BB","CW","E","FD","HW","YC")
sp <- c("Trembling Aspen","Balsam Fir","Western Red Cedar","Birch","Douglas-Fir","Western Hemlock","Yellow Cedar")
S <- data.frame(Code=co,Species=sp)
knitr::kable(
  S, booktabs = TRUE, row.names = FALSE
)
```

The natural join $R⋈S$ evaluates to:

```{r, echo=FALSE}
knitr::kable(
  inner_join(R,S), booktabs = TRUE, row.names = FALSE
)
```

## Outer Join

An **outer join** joins all the tuples of two relations based on a common attribute. The result is similar to a set union, except the input relations do not need to be union compatible. Formally, an outer join or sometimes called a full join is expressed as $R⟗S$, which  evaluates to:

```{r, echo=FALSE}
knitr::kable(
  full_join(R,S), booktabs = TRUE, row.names = FALSE
)
```

### Right and Left Outer Join

Sometimes, it may be desirable to join attributes or tuples from one relation, but not the other. For these cases, we can use either **right outer join** or **left outer join**. Formally, right outer join is expressed as $R⋉S$ and evaluates to:

```{r, echo=FALSE}
knitr::kable(
  right_join(R,S), booktabs = TRUE, row.names = FALSE
)
```

Formally, left outer join is expressed as $R⋊S$ and evaluates to:

```{r, echo=FALSE}
knitr::kable(
  left_join(R,S), booktabs = TRUE, row.names = FALSE
)
```

### Theta Join

We can also join relations conditionally and without sharing a common attribute, which is known as a **theta join** and expressed as $R⋈_θS$. To understand how a theta join works, it is useful to recognize that $R⋈_θS=σ_{θ}(R×S)$. As you can see, a theta join is simply a selection of a Cartesian product where theta $θ$ is the predicate. For example, $R⋈_{height>19}S$ evaluates to:

```{r, echo=FALSE}
knitr::kable(
  inner_join(R[which(R$Height>19),],S), booktabs = TRUE, row.names = FALSE
)
```

### Cardinality of Joins

Depending on the schema of the two relations being joined, the number of tuples joined from one relation to another can vary and is known as **cardinality**. In the simplest case, one tuple in $R$ is joined to one tuple in $S$, and this cardinality is known as **one-to-one** usually expressed as 1:1. The natural join example above, $R⋈S$, is an example of **one-to-many** (1:M) or **many-to-one** (M:1) cardinality because one species tuple found in $S$ corresponds to many species tuples in $R$. Finally, **many-to-many** (M:M) cardinality describes the case where there are multiple tuples in $R$ that correspond to multiple tuples in $S$. An example of a many-to-many relationship might be many species of trees in $R$ that correspond to many forest stands in $S$. In other words, a forest stand might be comprised of many species and any particular species might be found in many forest stands. Figure 5.7 illustrates how cardinality might emerge depending on the relational schema and problem at hand.

![Figure 5.7 Cardinality of joins between relations R and S.](images/05-07-join-cardinality.png){.center}

### Structured Query Language

Throughout this chapter, we have seen the various ways that relations are manipulated through relational algebra, Boolean logic, and joins. Since a GIS relies on a RDBMS to interact with data, especially data in the attribute table, geomatics professionals literally need a language to programmatically execute relational algebra, joins, and the other functions of a RDBMS within the GIS software. Such languages are known as query languages, each with its own syntax and use. By far, the most commonly used query language for RDBMS in GIS and across other systems is **Structured Query Language** abbreviated **SQL** and pronounced "sequel". SQL has five primary language elements:
1. Clauses state an action or operation;
2. Expressions evaluate to a value;
3. Predicates evaluate an expression using equivalency and Boolean operators;
4. Queries apply set selection on a predicate; and
5. Statements are the combination of all the elements above

SQL has numerous keywords, which are the actions that comprise a clause. It is beyond the scope of this textbook to describe all of them, but most of the SQL keywords are implemented within GIS software in other ways. For example, you would rarely need to programmatically `ADD` an attribute to a relation. Instead, you might click an "Add field" button within the GIS software you are using. Similarly, you might never programmatically `UPDATE` the value for a tuple because most GIS software will allow you to simply double-click a cell in the table and change the value. The primary action that is nearly always performed programmatically with proper SQL syntax is applying a query, which is what we will focus on for this section.

SQL queries are fundamental for implementing set selection $σ_{predicate}$ and they look like this:

```
SELECT attributes
FROM relation
WHERE predicate;
```

The entire form above is a statement, which is enclosed by a semi-colon at the end. The statement is comprised of three clauses using the keywords: `SELECT`,`FROM`, and `WHERE`. The `SELECT attributes` clause defines which attributes of the relation will be returned. You should recognize that this is the equivalent of applying a set projection $Π_{attributes}$ to the entire set selection statement. You can specify attributes by name (e.g., `SELECT Species`), but it is more common to return all of the attributes of the relation with an asterisk like `SELECT *`. The `FROM relation` clause defines which relation the selection is performed on. Keeping in mind that a RDBMS is comprised of many relations and at any given time you may have several different data sources open in your GIS software, the `FROM` keyword helps to clarify exactly which relation contains the attributes defined by the `SELECT` clause. Finally, the `WHERE predicate` clause defines the predicate that will be evaluated for the set selection, and this is where the magic happens. Although this is the formal syntax for a SQL query, most GIS software will usually only require the user to define the predicate, so next we will look at how to construct different SQL queries on our relation $R$.

Suppose we want to select the trees that are greater than 15 m, like in our previous equivalency example of $σ_{height>15}(R)$. The SQL statement looks like this `SELECT * FROM R WHERE height > 15;`. If we only want to return the species for tree heights greater than 15 m, then the SQL statement looks like this `SELECT Species FROM R WHERE height > 15;` and evaluates to:

```{r, echo=FALSE}
knitr::kable(
  data.frame(Species=R[which(R$`Height (m)`>15),4]), booktabs = TRUE, row.names = FALSE
)
```

The above SQL statement would be an example of $Π_{species}(σ_{height>15}(R))$. In SQL, the multiplication symbol has the arithmetic meaning and cannot be used to concatenate two predicates. For this reason, we have the Boolean operators for evaluating multiple predicates. For example, $(height>15)×(species=WesternHemlock)$ would be written in SQL as `SELECT * FROM R WHERE height > 15 AND species="Western Hemlock";`. Our previous example of using Boolean $NOT$ in SQL would be written as `SELECT * FROM R WHERE NOT species="Western Hemlock";`. These are all relatively simple examples, but it common to create more complicated queries that use several Boolean operators. Note here how the species value in the expression above is in quotation marks `"Western Hemlock"` because the data type of the species attribute is a _string_. By contrast, the height value in the previous expression is simply an _integer number_. It is important to emphasize at this point that the only equivalency operator that can be used with string data type attributes is $=$. In other words, `"Western Hemlock">"Douglas-Fir"` is illogical, cannot be evaluated, and will return an error. 

If you combine two or more Boolean operators into one statement, then they are evaluated in SQL according to the following precedence:
1. Anything enclosed within parentheses `()`
2. `NOT`
3. `AND`
3. `OR`
For example, `SELECT * FROM R WHERE dbh < 30 AND species="Douglas-Fir" OR species="Western Hemlock";` would evaluate to:

```{r, echo=FALSE}
knitr::kable(
  R[which(R$`DBH (cm)`<30 & R$Species=="Douglas-Fir" | R$Species=="Western Hemlock"),], booktabs = TRUE, row.names = FALSE
)
```

But if we want the `OR` to be evaluated before the `AND`, then we need to use parentheses like `SELECT * FROM R WHERE dbh < 30 AND (species="Douglas-Fir" OR species="Western Hemlock");`, which evaluates to:

```{r, echo=FALSE}
knitr::kable(
  R[which(R$`DBH (cm)`<30 & (R$Species=="Douglas-Fir" | R$Species=="Western Hemlock")),], booktabs = TRUE, row.names = FALSE
)
```

You may notice the case of $XOR$ conspicuously missing from the order above and this is because SQL does not natively implement the $XOR$ operator. If you want to evaluate the exclusive OR example used in the previous section, $(height>15)XOR(species=WesternHemlock)$, then you would construct a SQL statement like this `SELECT * FROM R WHERE (height > 15 OR species="Western Hemlock") AND NOT (species="Western Hemlock" AND height > 15);`. As you can see, SQL queries can quickly get complex and involve many Boolean operators, so it is important to understand operator precedence and whenever in doubt, you can always use parentheses to override any precedence rules. You should also recognize that there are many ways to write complex statements to achieve your desired selection and you should always prefer the simplest statement possible.

Finally, a very common query that involves returning all tuples that match an attribute value in a list of values can be applied using the `IN` operator in SQL. For example, suppose we want to select all conifer tree species (codes: BB, CW, FD, HW, and YC) from $S$ below:

```{r, echo=FALSE}
knitr::kable(
  S, booktabs = TRUE, row.names = FALSE
)
```

Your natural reaction to this problem might be to write a long SQL statement like `SELECT * FROM S WHERE code="BB" OR code="CW" OR code="FD" OR code="HW" OR code="YC";`. This is perfectly fine, but you can write this more economically with `IN` such as `SELECT * FROM S WHERE code IN("BB","CW","FD","HW","YC");`. Be aware that a common mistake is to write a long predicate using `OR` like `code="BB" OR "CW" OR "FD" OR "HW" OR "YC"`, but this is incorrect syntax in SQL. Remember that each side of an `OR` or `AND` operator is an _expression_ that evaluates to a Boolean truth value. So `code="BB" OR "CW"` will return an error because `"CW"` alone cannot be evaluated to a Boolean truth value.

#### TITLE HERE {#box-text -}

#### Introduction {-}

Vegetation diversity in urban landscapes is important to support urban forest biodiversity and residents’ mental health. The aim of this case study is to link together socioeconomical data and vegetation information to identify areas to prioritize intervention in the City of Vancouver. [The Canadian Index of Multiple Deprivation (CIMD)](https://www150.statcan.gc.ca/n1/pub/45-20-0001/452000012019001-eng.htm) data has four dimensions of population vulnerability scores and we will aggregate these scores to obtain an overall vulnerability score for each dissemination area (DA) in Vancouver. We will compute the vegetation diversity score using [street trees data](https://opendata.vancouver.ca/explore/dataset/street-trees/) and vegetation type cover richness data^[Obtained from reclassifying [Land Cover Classification 2014 - 2m Raster](http://www.metrovancouver.org/data) to one vegetation class and five vegetation classes and counted the number of vegetation type cover classes using the `Zonal Histogram` Tool.] and then use query to identify priority areas.

#### Join {-}

The raw CIMD tabular data includes the DA code and the corresponding vulnerability scores (table 1). In order to visualize these scores on a map, we will need to relate these scores to spatial data that include the information about the DA polygons and the coordinate pairs associated with each DA. Hence, a polygon shapefile of the DAs in Vancouver^[Extracted by clipping the [Canada-wide dissemination areas boundary](https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2016-eng.cfm) to the [City of Vancouver's municipality boundary](https://opendata.vancouver.ca/explore/dataset/city-boundary).] is obtained, and its attributes are shown in Table 2.

```{r, echo=FALSE}
CIMD <- read.csv("data/05/bc_CIMD_scores.csv")
colnames(CIMD) <- c("PRCDDA", "Province","DA population", "Ethno-cultural composition quintiles", "Ethno-cultural composition scores", "Situational vulnerability quintiles", "Situational vulnerability scores", "Economic dependency quintiles", "Economic dependency scores", "Residential instability quintiles", "Residential instability scores")
knitr::kable(
  head(CIMD), booktabs = TRUE,
  caption = 'An excerpt of the CIMD data table.'
)
```

```{r, include=FALSE}
VancouverDA <- readOGR(dsn = "data/05", layer = "VancouverDA")
```

```{r, echo=FALSE}
knitr::kable(
  head(VancouverDA@data), booktabs = TRUE,
  caption = 'An excerpt of the Vancouver DA polygon shapefile attributes.'
)
```

The tabular data of the CIMD scores are related to the DAs polygon by the DA code. The cardinality of the relationship between these two tables is one-to-one as each DA is described by one set of the CIMD scores. To join the CIMD scores to the Vancouver DA polygons, we would use the `PRCDDA` attribute in the CIMD table as the foreign key to perform a join on the `DAUID` attribute in the Vancouver DA polygon relation. Now that the CIMD scores are joined to the Vancouver DA polygon attribute table, we can create choropleth maps to display the vulnerability scores of the DAs (Figure 5.8).

```{r, include=FALSE}

DA_CIMD <- readOGR(dsn = "data/05", layer = "VancouverDA_CIMD")

DA_CIMD@data <- DA_CIMD@data %>%
  mutate_if(is.numeric,round, digits = 3)

DA_CIMD_proj <- spTransform(DA_CIMD, "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

pal <- colorNumeric(palette = "YlOrRd", domain = range(DA_CIMD@data$Situatio_1))

labels <- sprintf(
  "<strong>DAUID </strong> %s<br/><strong>Situational Vulnerabiltiy Score </strong> %g",
  DA_CIMD@data$DAUID, DA_CIMD@data$Situatio_1
) %>% lapply(htmltools::HTML)

m <- leaflet(DA_CIMD_proj) %>%
  addProviderTiles("CartoDB.Positron")%>%
  setView(lat = 49.255, lng = -123.153, zoom = 12) %>%
  addPolygons(fillColor = pal(DA_CIMD@data$Situatio_1), 
              weight = 0.6, 
              opacity = 1,
              color = "#c2c2c2",
              dashArray = NULL,
              fillOpacity = 0.8,
              highlight = highlightOptions(
                weight = 1.8, 
                color = "#6e6e6e",
                dashArray = NULL,
                fillOpacity = 0.7,
                bringToFront = TRUE),
              label = labels,
              labelOptions = labelOptions(
                style = list("font-weight" = "normal", padding = "3px 8px"), textsize = "12px", direction = "auto"
              )) %>%
  addLegend(pal = pal, values = ~DA_CIMD@data$Situatio_1, opacity = 0.7, 
            title = "Situational Vulnerabiltiy Score",
            position = "bottomleft")
```

```{r, echo=FALSE, out.width = '100%', fig.align = 'center', fig.cap = 'Figure 5.8. An example of choropleth map displaying the situational vulnerability scores in the City of Vancouver at DA level. Higher score represents the DA has higher situational vulnerable population (e.g., population lacking a high school diploma, low-income population).'}

m

```

#### Calculation

Suppose we would like to calculate the overall vulnerability score for each DA. We would first name a new field (e.g., "aggregate_score"), set the data type to double (to allow negative values and values with decimal places), and then enter the mathematical expression to specify the calculation to sum the four dimensions of CIMD scores and divide it by four to obtain an averaged vulnerability score for each DA. Using similar steps, we could apply a min-max normalization to transform this overall vulnerability score to a range between 0 and 1 to allow for a quick interpretation of the score. The formula is as follows: $\frac{(X - X_{min})}{(X_{max} - X_{min})}$.

Using what you have learned, join the street tree data and the vegetation type cover richness data to the Vancouver DA attribute table and to compute a vegetation diversity score. The street trees data shows the number of unique street tree species at a DA. Make sure you apply a min-max normalization to obtain the street tree diversity score. The vegetation diversity score can be computed by averaging the normalized scores of the two vegetation data.

```{r, include=FALSE}
calculated <- readOGR(dsn = "data/05", layer = "Results")
calculated.full <- head(calculated@data[,c(1, 14, 15, 17, 16, 18, 21)])
colnames(calculated.full) <- c("DAUID","Aggregated scores", "Normalized aggregated scores", "Species count", "Street tree diversity", "Vegetation richness", "Vegetation diversity scores")
calculated.full <- calculated.full %>%
  mutate_if(is.numeric,round, digits = 3)
```

```{r, echo=FALSE}
knitr::kable(
  calculated.full, booktabs = TRUE,
  caption = 'An excerpt of the attribute table after the joins and calculations.'
)
```

```{r, include=FALSE}
full.results <- readOGR(dsn = "data/05", layer = "Results")
full.results_proj <- spTransform(full.results, "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
full.results_proj$norm_aggre <- round(full.results_proj$norm_aggre, 2)
full.results_proj$veg_div_sc <- round(full.results_proj$veg_div_sc, 2)
pal1 <- colorNumeric(palette = "Greens", domain = range(full.results_proj@data$veg_div_sc))

labels <- sprintf(
  "<strong>DAUID </strong>%s<br/> <strong>Vegetation Diversity Score </strong>%g<br/><strong>Normalized Aggregated Vulnerabiltiy Score </strong>%g",
  full.results_proj$DAUID, full.results_proj$veg_div_sc, full.results_proj$norm_aggre
) %>% lapply(htmltools::HTML)

m1 <- leaflet(full.results_proj) %>%
  addProviderTiles("CartoDB.Positron")%>%
  setView(lat = 49.255, lng = -123.1533, zoom = 12) %>%
  addPolygons(fillColor = ~pal1(full.results_proj$veg_div_sc),
              weight = 0.6,
              opacity = 1,
              color = "#ffffff",
              dashArray = NULL,
              fillOpacity = 0.7,
              highlight = highlightOptions(
                weight = 1.8, 
                color = "#7d7d7d",
                dashArray = NULL,
                fillOpacity = 0.7,
                bringToFront = TRUE),
              label = labels,
              labelOptions = labelOptions(
                style = list("font-weight" = "normal", padding = "3px 8px"),
                textsize = "12px", direction = "auto")) %>%
  addLegend(pal = pal1, values = ~full.results_proj$veg_div_sc, opacity = 0.7, 
            title = "Vegetation Diversity Score",
            position = "bottomleft")
```

Figure 5.9 shows a map of the vegetation diversity score at the DA level in Vancouver. The vegetation diversity score and the normalized aggregated vulnerability score are linked to each DA and can be viewed as you hover o-ver the DA.

```{r, echo=FALSE, out.width = '100%', fig.align = 'center'}
m1
```

#### Query  

Areas with a higher proportion of vulnerable populations and less variety of vegetation to support resident’s mental wellbeing are more in need for intervention. Supposed we define the priority area as DAs with a normalized aggregated vulnerability score greater than or equal to 0.5 and a vegetation diversity score less than 0.5. We could use the `Select By Attributes` tool to identify these priority areas by entering the appropriate query expression.

```{r, include=FALSE}
query.results <- calculated@data[calculated@data$norm_aggre >= 0.5 & calculated@data$veg_div_sc < 0.5,]
query.results <- query.results[,c(1,15,16,18,21)]
colnames(query.results) <- c("DAUID", "Normalized aggregated scores", "Street tree diversity", "Vegetation richness", "Vegetation diversity scores")
query.results <- query.results %>%
  mutate_if(is.numeric,round, digits = 3)
```

```{r, echo=FALSE}
knitr::kable(
  query.results, booktabs = TRUE,
  caption = 'Query result shows five records matched the priority area requirements.'
)
```

:::: {.box-content .call-out-content}

::: {.box-title .call-out-top}
#### Remember this? {-}
:::

<p id="box-text">Models are abstractions of reality and help us understand and communicate complex ideas.</p>

::::

## Summary

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa.

### Reflection Questions {-}

1. Explain ipsum lorem.
2. Define ipsum lorem.
3. What is the role of ispum lorem?
4. How does ipsum lorem work?

### Practice Questions {-}

2. Given ipsum, solve for lorem.
3. Draw ipsum lorem.

## Recommended Readings {-}

Ensure all inline citations are properly referenced here.

```{r include=FALSE}
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'htmlwidgets', 'webshot', 'DT',
  'miniUI', 'tufte', 'servr', 'citr', 'rticles'
), 'packages.bib')
```

<!--chapter:end:05-relational-databases.Rmd-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(networkD3)
```


# Network Analysis

Networks are abstract structures used to represent patterns of relationships among sets of various "things" [@ajorlouIntroductionNetworkModels2018]. Such structures can be used to represent social connections, spatial patterns, ecological relationships, etc. In GIS, the elements that compose geospatial networks are geolocated -- in other words: they have latitude and longitude values attached to them. Network analysis encompasses a series of techniques used to interpret information from those networks. This chapter introduces basic concepts for building, analyzing and applying spatial networks to real-world problems.


:::: {.box-content .learning-objectives-content}

::: {.box-title .learning-objectives-top}

#### Learning Objectives {-}

:::
<p id="box-text">By the end of the chapter, students will be able:</p>


1. To understand what networks are and to identify the elements that compose them;
1. To categorize different types of networks according to their topologies;
1. To create spatial networks and learn how to apply them in various applications;
1. To extract relevant information from spatial networks about the relationship between their elements, such as routes, distances and centralities.
:::

### Key Terms {-}
Network analysis, Spatial networks, Graph theory

## Introduction to graph theory
Graphs are the abstract language of networks [@systemsinnovationGraphTheoryOverview2015]. Graph theory is the area of mathematics that study graphs. By abstracting networks into graphs, one is able to measure different kinds of indicators that represents information about relationships that exist within a certain system. This is especially useful to assess the state of complex adaptive systems such as societies, cities, ecosystems, etc. All graphs are composed of two parts: nodes and edges.

### Nodes
A node (or vertex) may represent any thing that can be connected with other things. For example, it can represent people in social networks, street intersections in road networks, or chemical compounds in molecular networks, among others.

### Edges
Edges, on the other hand, represent how vertices are interconnected to each other. So it may represent the vertices' social connections, street segments, molecular bindings, etc. The graph below represents rapid and frequent transit lines in Metro Vancouver. Each node represents a transit line and the edges represents connections between those lines.

```{r pressure, echo=FALSE}
data <- data.frame(
  from=c("Expo Line", "99-B Line", "R4", "Canada Line", "R4", "Millenium Line", "Millenium Line", "Seabus", "Seabus", "Seabus", "Expo Line", "R4", "West Coast Express", "West Coast Express", "R5", "R5", "West Coast Express", "Millenium Line", "West Coast Express",  "West Coast Express"),
  to=c("99-B Line", "Canada Line", "Canada Line", "Expo Line", "Expo Line", "Expo Line", "99-B Line", "Canada Line", "Expo Line", "R2", "R1", "99-B Line", "Expo Line", "Millenium Line", "Expo Line", "Canada Line", "R3", "R3", "Seabus", "Canada Line")
)

simpleNetwork(data, charge=-500, linkDistance=50, fontSize=10)
```
<p class="codeblock-label">Graph representing Metro Vancouver rapid and frequent transit network</p>


![Rapid and frequent transit network in Metro Vancouver. Source: City of Pitt Meadows](https://www.pittmeadows.ca/sites/default/files/docs/23-07-2019_2-47-50_pm.jpg).(images/metro_vancouver_transit_network.jpeg){.center}


## Connectivity and order
There are two major types of connections within the graphs: directed and undirected. Connections are directed when they have a specific node of origin and destination. 

### Direct
Directed graphs are networks where the order of elements change relationships between them. We represent directed connections with an arrow. For example, in the case of the transit network we could use a directed graph to represent the path one has to take in order to shift from one line to another.

### Undirect
On the other hand, in an undirected graph, connections are represented as simple lines instead of arrows. The order of elements does not matter.

## Network topologies
Topology is the study of how network elements are arranged. The same elements arranged in different ways can change the network structure and dynamics. A very common example is the arrangement of computer networks [@wikibooksCommunicationNetworksNetwork2018].

### Physical versus logical topology

### Lines
Nodes are arranged in series where every node has no more than two connections.
(Example: Skytrain transit line)

### Rings
Every node has no mode than two connections and the "first" and "last" nodes are connected to each other forming a circle.
(Example: Stanley park seawall trail)

### Meshes
Every node is connected to more than one node.
(Example: Tree canopy)

### Stars
Two or more nodes arranged around a central node.
(Example: Courtyard apartment)

### Trees
Nodes are structured from a root node arranged into a number of smaller nodes.
(Example: Boat marinas)

### Buses
Nodes are structured with one connection around a central path.
(Example: Building-street connections)
 
### Fully connected
Every node is connected to every other node.
(Example: Soccer field visibility)

## Spatial Network Analysis

### Network tracing

### Linear referencing
[@ramsey23LinearReferencing2012].

### Routing
[@systemsinnovationNetworkDiffusionContagion2015].

### Least cost paths

### Least cost corridors

## Network Centrality
[@ajorlouIntroductionNetworkModels2018].

### Degree centrality
The number of connections of each node.

### Closeness centrality
How close the node is to every other node of the graph in logical distance.

### Betweenness centrality
How likely a node is to be passed through when going from every node to every other node of the graph.

:::: {.box-content .case-study-content}

::: {.box-title .case-study-top}
#### Case Study {-}
:::

#### Central and peripheral green spaces in Vancouver? {#box-text -}
[@mantegnaUBCChangingClimate2021]
<p id="box-text"></p>

<p id="box-text"></p>

<p id="box-text"></p>

::::


<!--chapter:end:08-network-analysis.Rmd-->

# LiDAR Acquisition and Analysis {#LiDAR-acquisition-and-analysis}

**Bold Text**, *Italicized Text* Regular Text.

::: {.box-content .learning-objectives-content}
::: {.box-title .learning-objectives-top}
#### Learning Objectives {.unnumbered}
:::

1.  Understand *how* LiDAR works
2.  Understand *what* we can do with LiDAR data
3.  Understand the basic processing steps required to use LiDAR data in a forestry context
:::

### Key Terms {.unnumbered}

LiDAR, ALS, Surface Models, LiDAR Metrics, Area-Based Approach, Individual Tree Detection

## What is LiDAR?

LiDAR is an active remote sensing technology that uses a laser scanner and time of flight principles to collect 3 dimensional data. A LiDAR system is made up of three components; a laser-scanning device, and accurate global navigation satellite system (GNSS), and an inertial measurement unit (IMU). The GNSS receiver allows the position of the laser to be determined in space, while the IMU records the orientation of the laser (i.e. roll, pitch, and yaw). When discussing LiDAR in an airborne context, we can also call it airborne laser scanning (ALS).

### How does it Work?

Typical LiDAR systems use the time of flight method to produce 3D data. A laser ranging instrument produces a short, intense pulse of light from the instrument to a target being measured. Some of this energy is then reflected back to the instrument, where it is recorded. Since the speed of light, and the location of the laser ranging instrument is known, we can calculate the position of the target by timing how long it takes between the the pulse being emitted and received.

![Figure X Concept of LiDAR.](images/15-Concept_of_LiDAR.png){.center}

A LiDAR dataset includes several pieces of information for each 3D point. X,Y,Z location data is included, as well as information about how the data was collected. In many cases, this includes

The most common file format for LiDAR files is called the LAS file format (.las). This file format was originally designed for 3-dimensional point cloud data, and is a free alternative to proprietary systems or a generic ASCII file interchange system. The main benefits of this file format are that it is relatively quick, can be used by any system, and stores information specific to the nature of LiDAR data wihtout being overly complex (:<https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities>).

LiDAR HISTORY

-   Early LiDAR point densities were low, which

-   Brief history in forestry / what can we do with LiDAR

![Figure X LiDAR System.](images/15-LiDAR_System.png){.center}

## Components of LiDAR Systems

### Lasers

-   4:10 - video 1
-   Typical wavelengths (eye safe, NIR vs green for bathymetric)
-   Power
-   Beam divergence - important to take into account. Think about a dinner plate compared to a bicycle wheel. A beam that has low divergence (dinner plate) will be able to distinguish more objects than a high divergence beam (bicycle wheel).
-   Target interaction - 7:45 in video 1
-   Scanning types - zig-zag, rotating mirror line, push broom (call back to RS chapter?) - video 2, 2:08
-   Pulse frequency, scan rate, scan angle

![Figure X LiDAR Unit.](images/15-LiDAR_Unit.jpg){.center}

### Position and Orientation

-   **Global Navigation Satellite Systems**

    -   Require us to know our position exactly!

    -   Callback to GNSS?

    -   On board GPS and GPS reference stations on the ground are used to post process the data in order to be as accurate as possible

![Figure X XYZ Coordinates.](images/15-XYZ_coordinates.jpg){.center}

-   **Inertial Measurement Unit (IMU)**

    -   An inertial measurement unit (IMU) consists of gyroscopes and accelerometers measures the attitude and acceleration of the aircraft along the X, Y, Z axis. This data is combined with the GNSS data to provide a precise location of the scanner in space.

    -   Mentioned elswhere? What is it - focus on image that discusses pitch/roll/yaw

-   **Clocks**

    -   The LiDAR point data needs to be synched with the positioning data in order to know where the point is in space. To do this, a very accurate GPS clock is used to time stamp the laser scanning data (7:30 video 2).

    -   Accurate clocks are imperative for producing accurate point clouds. One nanosecond corresponds to a 30 cm travel distance A - (video 1)

### Platform

LiDAR units can be attached to a variety of platforms. Traditionally, LiDAR units for forestry research were mounted on airplanes and helicopters, as units were large and cumbersome [Figure X for actual scanner], however ground based units such as terrestrial laser scanning (TLS), and mobile laser scanning (MLS) have also been developed. These units tend to have a very high point density, and TLS is often used in modeling tree architecture.

-   Plane vs helicopter - what is normal

-   Drone: As technology has improved and laser units have gotten smaller, we can mount LiDAR units to drones (also known as...)

![Figure X Drone mounted LiDAR.](images/15-LiDAR_on_Drone_2.jpg){.center}

-   MLS/backpack

-   Satellite based:

    -   ICESat

    -   GEDI

![Figure X GEDI.](images/15-GEDI.jpg){.center}

-   Cars: Don't need figure..

![Figure X Mobile LiDAR System.](images/15-Mobile_LiDAR.jpg){.center}

-   TLS

**IDEA**: combine different types into one collage


## Types of LiDAR

### Discrete Return

Discrete return LiDAR = more common. Include figure of a cross-section!

### Full Waveform

### Multispectral
- New

### Single Photon Lidar
- New

![Figure X LiDAR Discrete vs Full Waveform.](images/15-LiDAR_Discrete_Full_Waveform.png){.center}

[This is how we link to something. {target="\_blank"} ensures that this link opens in a new window rather than navigating away from the textbook.](https://google.com){target="_blank"}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit.

::: {.box-content .call-out-content}
::: {.box-title .call-out-top}
#### Call out {.unnumbered}
:::

<p id="box-text">

This is a call out. Put some important concept or fact in here.

</p>
:::

## LiDAR Derivatives and Analysis

-   What can we do with LiDAR derivatives, why are they important
-   What is the use for LiDAR in forestry and ecology - examples from NCC LiDAR Lecture
- How do we go from raw cloud to these derivatives

![Figure X typical LiDAR point cloud.](images/15-las_denoise.png){.center}

### Bare Earth Elevation

-   What is a DEM

![Figure X DEM.](images/15-las_dem.png){.center}

### Canopy Height Model

-   What is a CHM

![Figure X CHM.](images/15-las_CHM_2D.png){.center}

### Canopy Surface Model

-   CHM vs DSM?

### Grid Metrics

-   What are these used for

![Figure X DEM.](images/15-las_hmax_2D.png){.center}

![Figure X DEM.](images/15-las_metrics_2D.png){.center}

### Tree Segmentation

-How and why would we want too do this

![Figure X Processing Flowchart.](images/15-Processing_Flowchart.png){.center}

![Figure X DEM.](images/15-las_treetops.png){.center}

### Software

We use lidR for this section.. Can use XYZ

::: {.box-content .case-study-content}
::: {.box-title .case-study-top}
#### Case Study {.unnumbered}
:::

#### Creating LiDAR Metrics from a Raw Point Cloud {#box-text .unnumbered}

<p id="box-text">

For this case study, we will be using a clipped .las file from the 2018 open LiDAR dataset of City of Vancouver and UBC Endowment Lands in British Columbia (we randomly selected a 200 x 200 meter portion of the '4840E_54550N' tile, see below for the link where you can download the data), and the `lidR` package in R. The script to process this data is included HERE [where to include script?], and you can use the `lidR` book [link] to get a more in depth understanding of the functions we apply below.

</p>

<p id="box-text">

The first step when looking at LiDAR data is to inspect it; we recommend using the free software CloudCompare (link below), or the `plot()` function in the `lidR` package. Once we have a sense of our data, we can clean and filter the data, using `classify_noise()` and the '-drop' switch to get rid of the noise in our dataset [include image showing noisy vs. clean data?]. Our cleaned dataset can then be used to create a DEM; first we can `classify_ground()`, followed by using the `grid_terrain()` function [call back to previous chapter] -- this is an essential step that could require quite a bit of tweaking depending on what you want to use the DEM for! In our case, the DEM is used to *normalize* the point cloud. Normalization removes the effect of terrain on above ground measurements, allowing comparisons of vegetation heights. [insert image of DEM and CHM]. The normalized point cloud is used to create our CHM (created using `grid_canopy()`). It is at this point that we can analyze the point cloud in a variety of ways. We can use an area-based approach (ABA) to create metrics at the grid level (`grid_metrics()`), or we can derive metrics at the individual tree scale. In order to do this we need to first segment the trees (`segment_trees()`) before creating metrics (`tree_metrics()`). Below we can see an example of a segmented point cloud.

</p>

<p id="box-text">

Case studies should have at least one image or map (no more than 2 total) and the written length should be around 300 words (shown above). Any references to external literature should by hyperlinked with the Digitial Object Identifier (DOI) permanent URL and [entered into the bibliography](https://bookdown.org/yihui/bookdown/citations.html){target="_blank"}. Avoid linking to external resources without a DOI and permanent URL. Contact Paul or try using the Leaflet package in R if you want to add an interactive web map.

</p>
:::

::: {.box-content .your-turn-content}
::: {.box-title .your-turn-top}
#### Your turn! {.unnumbered}
:::

<p id="box-text">

Explore some of the LiDAR derivatives that we produced in the case study above

</p>

<p id="box-text">

Interactive map of rasters:

-   DEM

-   CHM

-   and some grid metrics - e.g. mean and p99?

    </p>

<p id="box-text">

Screenshot vs. interactive point cloud - data size concerns

</p>

<p id="box-text">

Necessity of being able to rotate point cloud? Relatively little gain for trouble of small area.

</p>

Your browser does not support iframes

</p>

</iframe>
:::

## Summary

LiDAR! Requires 3 components. Important for vertical characterization of the forest. Can produce useful rasters


### Reflection Questions {.unnumbered}

1.  Explain ipsum lorem.
2.  Define ipsum lorem.
3.  What is the role of ispum lorem?
4.  How does ipsum lorem work?

### Practice Questions {.unnumbered}

2.  Given ipsum, solve for lorem.
3.  Draw ipsum lorem.

`r if (knitr::is_html_output()) ' ## Recommended Readings {-} '`

Ensure all inline citations are properly referenced here.

```{r include=FALSE}
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'htmlwidgets', 'webshot', 'DT',
  'miniUI', 'tufte', 'servr', 'citr', 'rticles'
), 'packages.bib')
```

<!--chapter:end:15-LiDAR-acquisition-and-analysis.Rmd-->

